# Step 1: Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# Step 2: Load Dataset
df = pd.read_csv(r"D:\machine Learning\sales_data_sample.csv", encoding='latin1')
print(df.head())
print(df.info())

# Select numeric columns (you can choose others as needed)
num_df = df.select_dtypes(include=[np.number])

# Check for missing values
print(num_df.isnull().sum())

# Drop rows with missing values (optional)
num_df = num_df.dropna()

# Select numeric columns (you can choose others as needed)
num_df = df.select_dtypes(include=[np.number])

# Check for missing values
print(num_df.isnull().sum())

# Drop rows with missing values (optional)
num_df = num_df.dropna()

features = num_df[['QUANTITYORDERED', 'PRICEEACH', 'SALES', 'MSRP']]


scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)

inertia = []
K_range = range(1, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(scaled_features)
    inertia.append(kmeans.inertia_)

# Plot the Elbow graph
plt.figure(figsize=(8,5))
plt.plot(K_range, inertia, marker='o')
plt.title("Elbow Method for Optimal K")
plt.xlabel("Number of Clusters (K)")
plt.ylabel("Inertia (SSE)")
plt.show()

kmeans = KMeans(n_clusters=4, random_state=42)
df['Cluster'] = kmeans.fit_predict(scaled_features)

print("\nCluster Centers (scaled):\n", kmeans.cluster_centers_)

# Show number of points in each cluster
print("\nCluster Counts:\n", df['Cluster'].value_counts())

# Compute average of numeric features per cluster
cluster_summary = df.groupby('Cluster')[['QUANTITYORDERED','PRICEEACH','SALES','MSRP']].mean()
print("\nCluster Summary:\n", cluster_summary)

plt.figure(figsize=(8,6))
plt.scatter(df['SALES'], df['PRICEEACH'], c=df['Cluster'], cmap='viridis')
plt.xlabel('Sales')
plt.ylabel('Price Each')
plt.title('K-Means Clustering (Sales vs Price)')
plt.show()
